{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2027b5e-e41c-478f-9f62-0401792651f6",
   "metadata": {},
   "source": [
    "Author: Emily Wong \\\n",
    "April 23, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c7e1be-5ddd-4911-9a86-03519a5e0df4",
   "metadata": {},
   "source": [
    "# 1. Import libraries, methods, and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9eaeb-a2e6-47d0-a7c0-886d00fbe0c6",
   "metadata": {},
   "source": [
    "## 1.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7304b8d-d3fb-4a48-b6fd-6e9b239a0e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import uniform, normal, seed\n",
    "\n",
    "# Machine learning\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, balanced_accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scipy\n",
    "from scipy.stats import randint\n",
    "import xgboost as xgb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "# Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # for kernel density plots\n",
    "\n",
    "# for nested dictionary (calc_weights method)\n",
    "import collections\n",
    "def makehash():\n",
    "    return collections.defaultdict(makehash)\n",
    "\n",
    "# Fairness\n",
    "import aif360\n",
    "import fairlearn\n",
    "from fairlearn.metrics import demographic_parity_difference, demographic_parity_ratio, equalized_odds_difference, equalized_odds_ratio, false_negative_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ff032-c721-4d7f-8987-17837b27eb67",
   "metadata": {},
   "source": [
    "## 1.2 Reweighing Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0268d1-547f-41cb-b0b6-5ee1b2ab1c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_weights(df, sens_features_name, outcome_name):\n",
    "    ''' Calculate sample weights according to calculationg given in \n",
    "           F. Kamiran and T. Calders,  \"Data Preprocessing Techniques for\n",
    "           Classification without Discrimination,\" Knowledge and Information\n",
    "           Systems, 2012.\n",
    "    ''' \n",
    "    \n",
    "    # combination of label and groups (outputs a table)\n",
    "    sens_features = df[sens_features_name]\n",
    "    outcome = df[outcome_name]\n",
    "    tab = pd.DataFrame(pd.crosstab(index=sens_features, columns=outcome))\n",
    "\n",
    "    # reweighing weights\n",
    "    w = makehash()\n",
    "    n = len(df)\n",
    "    for r in tab.index:\n",
    "        key1 = str(r)\n",
    "        row_sum = tab.loc[r].sum(axis=0)\n",
    "        for c in tab.columns:\n",
    "            key2 = str(c)\n",
    "            col_sum = tab[c].sum()\n",
    "            if tab.loc[r,c] == 0:\n",
    "                n_combo = 1\n",
    "            else:\n",
    "                n_combo = tab.loc[r,c]\n",
    "            val = (row_sum*col_sum)/(n*n_combo)\n",
    "            w[key1][key2] = val\n",
    "    \n",
    "    # Instance weights\n",
    "    instance_weights = []\n",
    "    for index, row in df.iterrows():\n",
    "        race = row[sens_features_name]\n",
    "        out = row[outcome_name]\n",
    "        instance_weights.append(w[race][str(out)])\n",
    "\n",
    "    return instance_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6855166-414b-46c8-8dbf-9b8dc158e238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_eval(model, model_label, X_train, Y_train, X_test, Y_test, outcome_label, W=None, verbose=False):\n",
    "    results = []\n",
    "    o = outcome_label\n",
    "    \n",
    "    # Fit model\n",
    "    if W is None:\n",
    "        model.fit(X_train,Y_train)\n",
    "    else:\n",
    "        model.fit(X_train,Y_train, sample_weight=W)\n",
    "    \n",
    "    # Model predictions on test\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Test performance metrics\n",
    "    test_f1 = np.round(f1_score(Y_test,y_pred),3)\n",
    "    test_precision = np.round(precision_score(Y_test,y_pred),3)\n",
    "    test_recall = np.round(recall_score(Y_test,y_pred),3)\n",
    "    test_balanced_acc = np.round(balanced_accuracy_score(Y_test,y_pred),3)\n",
    "    test_auc = np.round(roc_auc_score(Y_test,y_pred_prob),3)\n",
    "    \n",
    "    # Print model performance\n",
    "    if verbose == True:\n",
    "        print('Test AUC:', test_auc)\n",
    "        print('Test Balanced Accuracy:', test_balanced_acc)\n",
    "        print('Test F1:', test_f1)\n",
    "        print('Test Precision:', test_precision)\n",
    "        print('Test Recall:', test_recall)\n",
    "        \n",
    "    # Prepare for fairness evaluation\n",
    "    y_pred = pd.DataFrame(y_pred,columns=['y_pred'])\n",
    "    y_pred_prob = pd.DataFrame(y_pred_prob,columns=['y_pred_prob'])\n",
    "    test_set = pd.concat([y_pred,y_pred_prob,Y_test.reset_index(drop=True),X_test.reset_index(drop=True)],axis=1)\n",
    "\n",
    "    if len(test_set[o][test_set['MOM_RACE_White']==1].unique()) < 2:\n",
    "        auc_white = None\n",
    "    else:\n",
    "        auc_white = np.round(roc_auc_score(test_set[o][test_set['MOM_RACE_White']==1],test_set['y_pred_prob'][test_set['MOM_RACE_White']==1]),3)\n",
    "    \n",
    "    # Demographic parity\n",
    "    p_white = np.mean(test_set['y_pred'][test_set['MOM_RACE_White']==1])\n",
    "    \n",
    "    # TP and FN\n",
    "    pos_lab_set_white = test_set[(test_set[o]==1) & (test_set['MOM_RACE_White']==1)]\n",
    "    pos_lab_set_white['fn'] = np.where(pos_lab_set_white['y_pred']==0,1,0)\n",
    "    fn_white = np.mean(pos_lab_set_white['fn'])\n",
    "    pos_lab_set_white['tp'] = np.where(pos_lab_set_white['y_pred']==1,1,0)\n",
    "    tp_white = np.mean(pos_lab_set_white['tp'])\n",
    "    \n",
    "    # FP, TN\n",
    "    neg_lab_set_white = test_set[(test_set[o]==0) & (test_set['MOM_RACE_White']==1)]\n",
    "    neg_lab_set_white['fp'] = np.where(neg_lab_set_white['y_pred']==1,1,0)\n",
    "    fp_white = np.mean(neg_lab_set_white['fp'])\n",
    "    neg_lab_set_white['tn'] = np.where(neg_lab_set_white['y_pred']==0,1,0)\n",
    "    tn_white = np.mean(neg_lab_set_white['tn'])\n",
    "        \n",
    "    if W is None:\n",
    "        reweigh_yn = 'No'\n",
    "    else:\n",
    "        reweigh_yn = 'Yes'\n",
    "    \n",
    "    for r in races:\n",
    "        pos_lab = test_set[(test_set[o]==1) & (test_set[r]==1)]\n",
    "        pos_lab['fn'] = np.where(pos_lab['y_pred']==0,1,0)\n",
    "        pos_lab['tp'] = np.where(pos_lab['y_pred']==1,1,0)\n",
    "        \n",
    "        neg_lab = test_set[(test_set[o]==0) & (test_set[r]==1)]\n",
    "        neg_lab['fp'] = np.where(neg_lab['y_pred']==1,1,0)\n",
    "        neg_lab['tn'] = np.where(neg_lab['y_pred']==0,1,0)\n",
    "        \n",
    "        if len(test_set[o][test_set[r]==1].unique()) < 2:\n",
    "            auc = None\n",
    "        else:\n",
    "            auc = np.round(roc_auc_score(test_set[o][test_set[r]==1],test_set['y_pred_prob'][test_set[r]==1]),3)\n",
    "            \n",
    "        if auc_white == None or auc == None:\n",
    "            auc_diff = None\n",
    "        else:\n",
    "            auc_diff = auc - auc_white\n",
    "        \n",
    "        results.append({'Model': model_label,\n",
    "                        'Reweigh': reweigh_yn,\n",
    "                        'Iteration': i+1,\n",
    "                        'Overall Test BA': test_balanced_acc,\n",
    "                        'Overall Test AUC': test_auc,\n",
    "                        'Overall Test F1': test_f1,\n",
    "                        'Overall Test Precision': test_precision,\n",
    "                        'Overall Test Recall': test_recall,\n",
    "                        'Race': r,\n",
    "                        'DP': np.mean(test_set['y_pred'][test_set[r]==1])-p_white,\n",
    "                        'FN':np.mean(pos_lab['fn']),\n",
    "                        'FN diff':np.mean(pos_lab['fn'])-fn_white,\n",
    "                        'TP':np.mean(pos_lab['tp']),\n",
    "                        'TP diff':np.mean(pos_lab['tp'])-tp_white,\n",
    "                        'FP': np.mean(neg_lab['fp']),\n",
    "                        'FP diff': np.mean(neg_lab['fp'])-fp_white,\n",
    "                        'TN': np.mean(neg_lab['tn']),\n",
    "                        'TN diff': np.mean(neg_lab['tn'])-tn_white,\n",
    "                        'Test AUC':auc,\n",
    "                        'Test AUC diff':auc_diff\n",
    "                       })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740d2e8-af9c-4f91-b08f-49e073dc00de",
   "metadata": {},
   "source": [
    "## 1.3. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d5158d-a1e7-44ee-bc96-83872a364881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = pd.read_excel(\"Eynav cleaned data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c280642-2dc3-4604-8a08-5593f4ea733a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract relevant variables for model fitting\n",
    "outcome = 'EPDS_risk2'\n",
    "data = all_data[['MOM_AGE','MOM_RACE','ETHNIC_GROUP','ZIP','MARITAL_STATUS','FINANCIAL_CLASS',\n",
    "                 'LBW','PTB',\n",
    "                 'DELIVERY_METHOD','NICU_ADMIT','MFCU_ADMIT',\n",
    "                 'PREE','GDM','GHTN',\n",
    "                 'MOM_BMI','MOM_LOS','CHILD_LOS',\n",
    "                 'HIST_ANXIETY','HIST_DEPRESS','HIST_BIPOLAR','HIST_PMAD','MENTAL_HEALTH_DX_CUTOFF',\n",
    "                 'MED_PSYCH','MED_CARDIO',\n",
    "                 outcome]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ddfc81-a213-4077-a476-a9133b941b89",
   "metadata": {},
   "source": [
    "## 1.3.3. Curate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2829b-4b79-4540-9de3-963432722234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.dropna() # keep only complete data\n",
    "print(\"N:\",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ed39c-8fcc-4e4a-9815-3fadb112d65b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# binary-class\n",
    "count0, count1 = data[outcome].value_counts()\n",
    "print(count0, count1)\n",
    "\n",
    "x = ['0','1']\n",
    "y = [count0, count1]\n",
    "plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb70876a-2439-4feb-9eb7-80b3b5c42705",
   "metadata": {},
   "source": [
    "## 1.3.4. Weight Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9edb6a-ac6a-4fce-a630-3aa184c70f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['w'] = calc_weights(df=data, sens_features_name=\"MOM_RACE\", outcome_name=outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef39be7-18ca-4472-8d60-94e27e1bf103",
   "metadata": {},
   "source": [
    "## 1.3.5. Get Dummies and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f1b66-2d4d-4946-beb2-84c5cf66cd51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get dummy variables\n",
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1776d1-d791-442e-8088-df078e882ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split into X and y\n",
    "X = data.drop([outcome], axis=1)\n",
    "Y = data[[outcome]]\n",
    "\n",
    "race = data[['MOM_RACE_Asian or Native Hawaiian or Other Pacific Islander',\n",
    "             'MOM_RACE_Black or African American',\n",
    "             'MOM_RACE_Multiracial',\n",
    "             'MOM_RACE_Other',\n",
    "             'MOM_RACE_Unknown',\n",
    "             'MOM_RACE_White',\n",
    "             'MOM_RACE_Hispanic White']]\n",
    "strat_df = pd.concat([Y,race],axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.90, test_size=0.10, shuffle=True, stratify=strat_df, random_state=1234) #random_state = 1234\n",
    "X_test = X_test.drop(['w'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c5621-89dd-42d3-b397-3b42517d1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "race = X_train[['MOM_RACE_Asian or Native Hawaiian or Other Pacific Islander',\n",
    "                'MOM_RACE_Black or African American',\n",
    "                'MOM_RACE_Multiracial',\n",
    "                'MOM_RACE_Other',\n",
    "                'MOM_RACE_Unknown',\n",
    "                'MOM_RACE_White',\n",
    "                'MOM_RACE_Hispanic White']]\n",
    "strat_df = pd.concat([y_train,race],axis=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.85, test_size=0.15, shuffle=True, stratify=strat_df, random_state=0) #random state_1234\n",
    "X_val = X_val.drop(['w'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74342e39-7fdf-40c0-b13e-47b4f54cc4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# binary-class\n",
    "count0_train, count1_train = y_train.value_counts()\n",
    "print(count0_train, count1_train)\n",
    "\n",
    "count0_val, count1_val = y_val.value_counts()\n",
    "print(count0_val, count1_val)\n",
    "\n",
    "count0_test, count1_test = y_test.value_counts()\n",
    "print(count0_test, count1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8279fc-a583-4003-8370-3156c6b3e51b",
   "metadata": {},
   "source": [
    "# 2. Handle imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9eeca-143a-43ef-8267-f856033ef710",
   "metadata": {},
   "source": [
    "## 2.2. Simple Under Sampling Majority (PMAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec6feb-0165-4b67-bc17-ce847624fc26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy = \"auto\", random_state=0)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "weights_rus = X_train_rus['w']\n",
    "X_train_rus = X_train_rus.drop(['w'], axis=1)\n",
    "y_train_rus.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b0d9a-4526-450f-b818-801ee4c46dd3",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436c426-f293-4bc8-9fae-889ec3613e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract weights and drop from training\n",
    "weights_train = X_train['w']\n",
    "X_train = X_train.drop(['w'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac9c47f-2b83-48f2-ba50-df573f21a4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "races = ['MOM_RACE_Asian or Native Hawaiian or Other Pacific Islander',\n",
    "         'MOM_RACE_Black or African American',\n",
    "         'MOM_RACE_Hispanic White',\n",
    "         'MOM_RACE_Multiracial',\n",
    "         'MOM_RACE_Other',\n",
    "         'MOM_RACE_Unknown',\n",
    "         'MOM_RACE_White'\n",
    "        ]\n",
    "\n",
    "orig_results = []\n",
    "n_trials = 100 # for finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54706e-b6e2-4c46-adc5-84a94eb2a1a6",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b3363-29ce-458e-87f2-5fb17f99123b",
   "metadata": {},
   "source": [
    "### Finetune XG Boost Classifier without Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b308cbc3-7dce-4a92-a329-b9441edd64a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = X_train_rus\n",
    "y = y_train_rus.values.ravel()\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"seed\":0,\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 10, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 5),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 1e-3, 1),\n",
    "        \"lambda\": trial.suggest_int(\"lambda\", 3, 100),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 100)\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(x, y, verbose=False)\n",
    "    predictions = model.predict(X_val)\n",
    "    predictions_prob = model.predict_proba(X_val)[:,1]\n",
    "    BA = balanced_accuracy_score(y_val, predictions)\n",
    "    AUC = roc_auc_score(y_val, predictions_prob)\n",
    "    return AUC\n",
    "\n",
    "#optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "sampler = optuna.samplers.TPESampler(seed=0, consider_prior=True, prior_weight=0.5) \n",
    "study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "study.optimize(objective, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93841b0e-59d7-4c82-b9b0-cb77043d1420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_xgb = xgb.XGBClassifier(objective='binary:logistic',verbosity=0, seed=0, **study.best_params)\n",
    "i = -1\n",
    "orig_XGB = pd.DataFrame(model_eval(model=best_xgb, model_label='XGB', X_train=x, Y_train=y, X_test=X_test, Y_test=y_test, outcome_label=outcome, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235d0ce-54d1-4e1b-a9b4-2be58f88beaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gain = best_xgb.get_booster().get_score(importance_type='gain')\n",
    "gain_sorted = dict(sorted(gain.items(), key=lambda x: x[1], reverse=False))\n",
    "\n",
    "features = list(gain_sorted.keys())\n",
    "values = list(gain_sorted.values())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(features,values)\n",
    "plt.yticks(fontsize=5.5)\n",
    "ax.set_xlabel(\"Gain\")\n",
    "plt.savefig('EPDS XGB Feature Importance (val).png',dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763ce61-145b-4f10-bfee-bc795233e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_xgb, 'best_xgb_epds_no_reweigh_val.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456163af-7dcd-4173-94a4-09acea9f4b8d",
   "metadata": {},
   "source": [
    "### Finetune XG Boost Classifier with Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e98efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = X_train_rus\n",
    "y = y_train_rus.values.ravel()\n",
    "w = weights_rus\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"seed\":0,\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 10, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 5),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 1e-3, 1),\n",
    "        \"lambda\": trial.suggest_int(\"lambda\", 10, 100),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 100)\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(x, y, sample_weight=w, verbose=False)\n",
    "    predictions = model.predict(X_val)\n",
    "    predictions_prob = model.predict_proba(X_val)[:,1]\n",
    "    BA = balanced_accuracy_score(y_val, predictions)\n",
    "    AUC = roc_auc_score(y_val, predictions_prob)\n",
    "    return AUC\n",
    "\n",
    "#optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "sampler = optuna.samplers.TPESampler(seed=0, consider_prior=True, prior_weight=0.5) \n",
    "study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "study.optimize(objective, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a31ce-6116-431f-89f6-b6de805cc5c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_xgb2 = xgb.XGBClassifier(objective='binary:logistic',verbosity=0, seed=0, **study.best_params)\n",
    "\n",
    "# original evaluation \n",
    "i = -1 # (will output as 0 since iteration = i+1)\n",
    "orig_XGB2 = pd.DataFrame(model_eval(model=best_xgb2, model_label='XGB', X_train=x, Y_train=y, X_test=X_test, Y_test=y_test, outcome_label=outcome, W=w, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1c1aa-2aa0-4034-83a5-edc7bc58ae26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gain = best_xgb2.get_booster().get_score(importance_type='gain')\n",
    "gain_sorted = dict(sorted(gain.items(), key=lambda x: x[1], reverse=False))\n",
    "\n",
    "features = list(gain_sorted.keys())\n",
    "values = list(gain_sorted.values())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(features,values)\n",
    "plt.yticks(fontsize=5.5)\n",
    "ax.set_xlabel(\"Gain\")\n",
    "plt.savefig('EPDS XGB Feature Importance Reweigh.png',dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a465a11c-6b1d-4793-b3c0-c93948c2c6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(best_xgb2, 'best_xgb_epds_reweigh_val.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05801c3f-dc88-4e80-b6c3-00dcce6cffa9",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece2000-9b22-4aa5-be54-30f5146c7d94",
   "metadata": {},
   "source": [
    "### Finetune Random Forest without Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1b873-e142-4eb2-b121-22b833fa4e01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = X_train_rus\n",
    "y = y_train_rus.values.ravel()\n",
    "\n",
    "def objective(trial):\n",
    "    params = {'random_state':0,\n",
    "             'max_features':'sqrt',\n",
    "             'ccp_alpha': trial.suggest_float(\"ccp_alpha\", 0, 1),\n",
    "             'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 50),\n",
    "             'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n",
    "             'n_estimators': trial.suggest_int('n_estimators', 1, 125),\n",
    "             'max_depth': trial.suggest_int('max_depth', 1, 5)\n",
    "             }\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(x, y)\n",
    "    predictions = model.predict(X_val)\n",
    "    predictions_prob = model.predict_proba(X_val)[:,1]\n",
    "    BA = balanced_accuracy_score(y_val, predictions)\n",
    "    AUC = roc_auc_score(y_val, predictions_prob)\n",
    "    return AUC\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0, consider_prior=True, prior_weight=0.5) \n",
    "study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "study.optimize(objective, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8bcbd9-7a7b-422b-91aa-1942f06f67cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(random_state=0,max_features='sqrt',**study.best_params)\n",
    "\n",
    "# original evaluation \n",
    "i = -1 # (will output as 0 since iteration = i+1)\n",
    "orig_RF = pd.DataFrame(model_eval(model=best_rf, model_label='RF', X_train=x, Y_train=y, X_test=X_test, Y_test=y_test, outcome_label=outcome, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5857b780-ebdf-405b-b6b0-193e6d60ee13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "imp_result = permutation_importance(\n",
    "    best_rf, X_test, y_test, n_repeats=10, random_state=2024, n_jobs=2\n",
    ")\n",
    "\n",
    "importance_mean = imp_result.importances_mean\n",
    "importance_sd = imp_result.importances_std\n",
    "\n",
    "ind = np.argpartition(importance_mean, -10)[-10:]\n",
    "top_feat = X_test.columns[ind]\n",
    "top_vals = importance_mean[ind]\n",
    "top_std = importance_sd[ind]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(top_feat,top_vals,xerr=top_std)\n",
    "ax.set_xlabel(\"Mean accuracy decrease\")\n",
    "plt.savefig('EPDS RF Feature Importance (val).png',dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1827b0c-58af-4582-8b92-112cf6b5151b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(best_rf, 'best_rf_epds_no_reweigh_val.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632da262-e2de-44fa-8c05-9dd292f87f2f",
   "metadata": {},
   "source": [
    "### Finetune Random Forest with Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e54b26-8ee9-4208-bf7e-1c534619841e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = X_train_rus\n",
    "y = y_train_rus.values.ravel()\n",
    "w = weights_rus\n",
    "\n",
    "def objective(trial):\n",
    "    params = {'random_state':0,\n",
    "             'max_features':'sqrt',\n",
    "             'ccp_alpha': trial.suggest_float(\"ccp_alpha\", 0, 1),\n",
    "             'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 50),\n",
    "             'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n",
    "             'n_estimators': trial.suggest_int('n_estimators', 1, 125),\n",
    "             'max_depth': trial.suggest_int('max_depth', 1, 5)\n",
    "             }\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(x, y, sample_weight=w)\n",
    "    predictions = model.predict(X_val)\n",
    "    predictions_prob = model.predict_proba(X_val)[:,1]\n",
    "    BA = balanced_accuracy_score(y_val, predictions)\n",
    "    AUC = roc_auc_score(y_val, predictions_prob)\n",
    "    return AUC\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0, consider_prior=True, prior_weight=0.5) \n",
    "study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "study.optimize(objective, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1104c3f5-41ed-45ce-a26c-7e98036870b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_rf2 = RandomForestClassifier(random_state=0,max_features='sqrt',**study.best_params)\n",
    "\n",
    "# original evaluation \n",
    "i = -1 # (will output as 0 since iteration = i+1)\n",
    "orig_RF2 = pd.DataFrame(model_eval(model=best_rf2, model_label='RF', X_train=x, Y_train=y, X_test=X_test, Y_test=y_test, outcome_label=outcome, W=w, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8897fc69-4fd0-4998-87d9-56d561559f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "imp_result = permutation_importance(\n",
    "    best_rf2, X_test, y_test, n_repeats=10, random_state=2024, n_jobs=2\n",
    ")\n",
    "\n",
    "importance_mean = imp_result.importances_mean\n",
    "importance_sd = imp_result.importances_std\n",
    "\n",
    "ind = np.argpartition(importance_mean, -10)[-10:]\n",
    "top_feat = X_test.columns[ind]\n",
    "top_vals = importance_mean[ind]\n",
    "top_std = importance_sd[ind]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(top_feat,top_vals,xerr=top_std)\n",
    "ax.set_xlabel(\"Mean accuracy decrease\")\n",
    "plt.savefig('EPDS RF Feature Importance Reweigh (val).png',dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b2450-2715-4713-81cf-d3ddf5b030e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(best_rf2, 'best_rf_epds_reweigh_val.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260997ed-80f7-43a6-bdb1-47f7fd488d41",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2efa24d-dd83-42b5-ab94-e404867038d2",
   "metadata": {},
   "source": [
    "### Finetune Logistic Regression without Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e985914-ec69-47f9-ab18-4ac90c27f433",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = X_train_rus\n",
    "y = y_train_rus.values.ravel()\n",
    "\n",
    "def objective(trial):\n",
    "    params = {'penalty':'l2',\n",
    "             'C':trial.suggest_loguniform(\"C\", 1e-2, 1),\n",
    "             'tol':trial.suggest_uniform('tol' , 1e-6 , 1e-3)\n",
    "             }\n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(x,y)\n",
    "    predictions = model.predict(X_val)\n",
    "    predictions_prob = model.predict_proba(X_val)[:,1]\n",
    "    BA = balanced_accuracy_score(y_val, predictions)\n",
    "    AUC = roc_auc_score(y_val, predictions_prob)\n",
    "    return AUC\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0, consider_prior=True, prior_weight=0.5) \n",
    "study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "study.optimize(objective, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1259f-74bd-488a-a6aa-354d3bace4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_glm = LogisticRegression(penalty='l2',**study.best_params)\n",
    "\n",
    "# original evaluation \n",
    "i = -1 # (will output as 0 since iteration = i+1)\n",
    "orig_GLM = pd.DataFrame(model_eval(model=best_glm, model_label='GLM', X_train=x, Y_train=y, X_test=X_test, Y_test=y_test, outcome_label=outcome, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f621369-70ef-4996-b7ff-e11d26eb8b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(best_glm, 'best_glm_epds_no_reweigh_val.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba107a-0f54-4d86-a80a-1a3c1f6ec58e",
   "metadata": {},
   "source": [
    "### Finetune Logistic Regression with Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084011d-209a-40e9-af4a-33d797274f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = X_train_rus\n",
    "y = y_train_rus.values.ravel()\n",
    "w = weights_rus\n",
    "\n",
    "def objective(trial):\n",
    "    params = {'penalty':'l2',\n",
    "             'C':trial.suggest_loguniform(\"C\", 1e-2, 1),\n",
    "             'tol':trial.suggest_uniform('tol' , 1e-6 , 1e-3)\n",
    "             }\n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(x, y, sample_weight=w)\n",
    "    predictions = model.predict(X_val)\n",
    "    predictions_prob = model.predict_proba(X_val)[:,1]\n",
    "    BA = balanced_accuracy_score(y_val, predictions)\n",
    "    AUC = roc_auc_score(y_val, predictions_prob)\n",
    "    return AUC\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0, consider_prior=True, prior_weight=0.5) \n",
    "study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "study.optimize(objective, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad889e-98e6-4ae5-94b0-716eb5ca09e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_glm2 = LogisticRegression(penalty='l2',**study.best_params)\n",
    "\n",
    "# original evaluation \n",
    "i = -1 # (will output as 0 since iteration = i+1)\n",
    "orig_GLM2 = pd.DataFrame(model_eval(model=best_glm2, model_label='GLM', X_train=x, Y_train=y, X_test=X_test, Y_test=y_test, outcome_label=outcome, W=w, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb6171-479b-421a-81d0-9c22ccf90743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(best_glm2, 'best_glm_epds_reweigh_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47377845-eb27-4b41-ac17-4e58bab4d6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orig_results = pd.concat([orig_XGB,orig_XGB2,orig_RF,orig_RF2,orig_GLM,orig_GLM2],axis=0)\n",
    "orig_results.to_excel(\"EPDS_orig_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca6bd11-fdf7-497c-997f-49ba753e9a65",
   "metadata": {},
   "source": [
    "# Boostrap Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c96197f-85f4-4624-9105-4aaed0dba4e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_glm = joblib.load('best_glm_phq9_no_reweigh_val.pkl')\n",
    "best_glm2 = joblib.load('best_glm_phq9_reweigh_val.pkl')\n",
    "\n",
    "best_rf = joblib.load('best_rf_phq9_no_reweigh_val.pkl')\n",
    "best_rf2 = joblib.load('best_rf_phq9_reweigh_val.pkl')\n",
    "\n",
    "best_xgb = joblib.load('best_xgb_phq9_no_reweigh_val.pkl')\n",
    "best_xgb2 = joblib.load('best_xgb_phq9_reweigh_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3e564-3ab4-42c2-a938-7d1bda7cb2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boot_test_results = pd.DataFrame()\n",
    "outcome = 'EPDS_risk2'\n",
    "for i in range(100):\n",
    "    test_set_boot = pd.concat([y_test,X_test],axis=1).sample(n=len(X_test), replace=True, random_state=i, ignore_index=True)\n",
    "    x = test_set_boot.drop([outcome], axis=1)\n",
    "    y = test_set_boot[outcome]\n",
    "        \n",
    "    boot_test_results = pd.concat([boot_test_results,pd.DataFrame(model_eval(model=best_xgb, model_label='XGB', X_train = X_train_rus, Y_train = y_train_rus.values.ravel(), X_test = x, Y_test = y, outcome_label=outcome, verbose=False))],axis=0)\n",
    "    boot_test_results = pd.concat([boot_test_results,pd.DataFrame(model_eval(model=best_xgb2, model_label='XGB', X_train = X_train_rus, Y_train = y_train_rus.values.ravel(), X_test = x, Y_test = y, outcome_label=outcome, W=weights_rus, verbose=False))],axis=0)\n",
    "    boot_test_results = pd.concat([boot_test_results,pd.DataFrame(model_eval(model=best_rf, model_label='RF', X_train = X_train_rus, Y_train = y_train_rus.values.ravel(), X_test = x, Y_test = y, outcome_label=outcome, verbose=False))],axis=0)\n",
    "    boot_test_results = pd.concat([boot_test_results,pd.DataFrame(model_eval(model=best_rf2, model_label='RF', X_train = X_train_rus, Y_train = y_train_rus.values.ravel(), X_test = x, Y_test = y, outcome_label=outcome, W=weights_rus, verbose=False))],axis=0)\n",
    "    boot_test_results = pd.concat([boot_test_results,pd.DataFrame(model_eval(model=best_glm, model_label='GLM', X_train = X_train_rus, Y_train = y_train_rus.values.ravel(), X_test = x, Y_test = y, outcome_label=outcome, verbose=False))],axis=0)\n",
    "    boot_test_results = pd.concat([boot_test_results,pd.DataFrame(model_eval(model=best_glm2, model_label='GLM',X_train = X_train_rus, Y_train = y_train_rus.values.ravel(), X_test = x, Y_test = y, outcome_label=outcome, W=weights_rus, verbose=False))],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f06c129-819f-4215-ad89-9f7e23884db7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boot_test_results.to_excel(\"EPDS_boot_test_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40da63-9719-41e9-a194-bd6cbba79317",
   "metadata": {},
   "source": [
    "# Evaluate Models Over Many Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e847400e-0ab3-4db6-b5ff-3d482a9d0a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outcome = 'EPDS_risk2'\n",
    "\n",
    "# split into X and y\n",
    "X = data.drop([outcome], axis=1)\n",
    "Y = data[[outcome]]\n",
    "repeat_results = pd.DataFrame()\n",
    "\n",
    "n_repeat = 10\n",
    "k_fold = 10\n",
    "for i in range(n_repeat):\n",
    "    kf = KFold(n_splits=k_fold, random_state=i, shuffle=True)\n",
    "    for k, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        \n",
    "        x_train = X.iloc[train_index]\n",
    "        y_train = Y.iloc[train_index]\n",
    "        \n",
    "        x_test = X.iloc[test_index]\n",
    "        x_test = x_test.drop(['w'], axis=1)\n",
    "        y_test = Y.iloc[test_index]\n",
    "        \n",
    "        rus = RandomUnderSampler(sampling_strategy = \"auto\", random_state=0)\n",
    "        x_train_rus, y_train_rus = rus.fit_resample(x_train, y_train)\n",
    "        weights_rus = x_train_rus['w']\n",
    "        x_train_rus = x_train_rus.drop(['w'], axis=1)\n",
    "        y_train_rus.value_counts()\n",
    "        \n",
    "        repeat_results = pd.concat([repeat_results,pd.DataFrame(model_eval(model=best_xgb, model_label='XGB', X_train = x_train_rus, Y_train = y_train_rus, X_test = x_test, Y_test = y_test, outcome_label=outcome, verbose=False))],axis=0)\n",
    "        repeat_results = pd.concat([repeat_results,pd.DataFrame(model_eval(model=best_xgb2, model_label='XGB', X_train = x_train_rus, Y_train = y_train_rus, X_test = x_test, Y_test = y_test, outcome_label=outcome, W=weights_rus, verbose=False))],axis=0)\n",
    "        repeat_results = pd.concat([repeat_results,pd.DataFrame(model_eval(model=best_rf, model_label='RF', X_train = x_train_rus, Y_train = y_train_rus, X_test = x_test, Y_test = y_test, outcome_label=outcome, verbose=False))],axis=0)\n",
    "        repeat_results = pd.concat([repeat_results,pd.DataFrame(model_eval(model=best_rf2, model_label='RF', X_train = x_train_rus, Y_train = y_train_rus, X_test = x_test, Y_test = y_test, outcome_label=outcome, W=weights_rus, verbose=False))],axis=0)\n",
    "        repeat_results = pd.concat([repeat_results,pd.DataFrame(model_eval(model=best_glm, model_label='GLM', X_train = x_train_rus, Y_train = y_train_rus, X_test = x_test, Y_test = y_test, outcome_label=outcome, verbose=False))],axis=0)\n",
    "        repeat_results = pd.concat([repeat_results,pd.DataFrame(model_eval(model=best_glm2, model_label='GLM',X_train = x_train_rus, Y_train = y_train_rus, X_test = x_test, Y_test = y_test, outcome_label=outcome, W=weights_rus, verbose=False))],axis=0)\n",
    "    print(\"Iteration\",i,\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690fb2e-b794-490a-8516-e04b67d528f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repeat_results.to_excel(\"EPDS_repeat_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f11594-5cca-4820-adf7-88f36b1ff098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save this file and output as html\n",
    "import os\n",
    "os.system('jupyter nbconvert --to html model_finetune_EPDS.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
